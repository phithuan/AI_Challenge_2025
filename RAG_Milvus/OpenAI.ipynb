{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e617989",
   "metadata": {},
   "source": [
    "# Build RAG with Milvus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b843db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Big_project_2025\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.1 at schema.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Big_project_2025\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.1 at common.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Big_project_2025\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.1 at milvus.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Big_project_2025\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.1 at rg.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Big_project_2025\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.1 at feder.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Big_project_2025\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.1 at msg.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# üìå Cell 1: Import th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "from pymilvus import MilvusClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "milvus_client = MilvusClient(uri=\"http://localhost:19530\")\n",
    "collection_name = \"my_rag_collection\"\n",
    "\n",
    "# üìå Cell 2: Load SentenceTransformer model load m√¥Ã£t l√¢ÃÄn duy nh√¢ÃÅt\n",
    "# Model s·∫Ω ƒë∆∞·ª£c t·∫£i v√† l∆∞u cache t·∫°i D:\\Big_project_2025\n",
    "model = SentenceTransformer(\n",
    "    'all-MiniLM-L6-v2',\n",
    "    cache_folder=\"D:/Big_project_2025\"\n",
    ")\n",
    "\n",
    "# H√†m ti·ªán √≠ch ƒë·ªÉ sinh embeddings cho text\n",
    "def emb_text(text): \n",
    "    return model.encode(text).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "640d23a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ S·ªë ƒëo·∫°n vƒÉn l·∫•y ƒë∆∞·ª£c: 13\n"
     ]
    }
   ],
   "source": [
    "# üìå Cell 3: ƒê·ªçc d·ªØ li·ªáu t·ª´ file .md\n",
    "# L·∫•y to√†n b·ªô file trong th∆∞ m·ª•c data\n",
    "text_lines = []\n",
    "for file_path in glob(r\"D:\\Big_project_2025\\RAG_Milvus\\data_Shop\\*.md\", recursive=True):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        file_text = file.read()\n",
    "    # C·∫Øt text theo header Markdown \"# ...\"\n",
    "    text_lines += file_text.split(\"# \")\n",
    "\n",
    "# Lo·∫°i b·ªè d√≤ng r·ªóng + strip kho·∫£ng tr·∫Øng\n",
    "text_lines = [line.strip() for line in text_lines if line.strip() and line]\n",
    "print(f\"‚úÖ S·ªë ƒëo·∫°n vƒÉn l·∫•y ƒë∆∞·ª£c: {len(text_lines)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84238fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 22.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ t·∫°o 13 embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# üìå Cell 4: T·∫°o embeddings cho d·ªØ li·ªáu\n",
    "embeddings = [emb_text(line) for line in tqdm(text_lines, desc=\"Creating embeddings\")]\n",
    "print(f\"‚úÖ ƒê√£ t·∫°o {len(embeddings)} embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c88ca275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è ƒê√£ x√≥a collection c≈©: my_rag_collection\n"
     ]
    }
   ],
   "source": [
    "# üìå Cell 5: K·∫øt n·ªëi Milvus\n",
    "milvus_client = MilvusClient(uri=\"http://localhost:19530\")\n",
    "collection_name = \"my_rag_collection\"\n",
    "\n",
    "# N·∫øu collection ƒë√£ t·ªìn t·∫°i th√¨ x√≥a ƒë·ªÉ t·∫°o m·ªõi\n",
    "if milvus_client.has_collection(collection_name):\n",
    "      milvus_client.drop_collection(collection_name)\n",
    "      print(\"‚ö†Ô∏è ƒê√£ x√≥a collection c≈©:\", collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3aa3c33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ t·∫°o collection: my_rag_collection\n"
     ]
    }
   ],
   "source": [
    "# üìå Cell 6: T·∫°o collection m·ªõi trong Milvus\n",
    "milvus_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    dimension=384,  # 384 = embedding size c·ªßa all-MiniLM-L6-v2\n",
    "    metric_type=\"IP\",  # Inner Product (ph√π h·ª£p cho similarity search)\n",
    "    consistency_level=\"Bounded\",\n",
    ")\n",
    "print(\"‚úÖ ƒê√£ t·∫°o collection:\", collection_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e5bb6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ ƒê√£ ch√®n 13 records v√†o Milvus collection 'my_rag_collection'\n"
     ]
    }
   ],
   "source": [
    "# üìå Cell 7: Chu·∫©n b·ªã d·ªØ li·ªáu v√† insert v√†o Milvus\n",
    "data = [\n",
    "    {\"id\": i, \"vector\": vec, \"text\": text}\n",
    "    for i, (text, vec) in enumerate(zip(text_lines, embeddings))\n",
    "]\n",
    "\n",
    "milvus_client.insert(collection_name=collection_name, data=data)\n",
    "print(f\"üéâ ƒê√£ ch√®n {len(data)} records v√†o Milvus collection '{collection_name}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f80115e",
   "metadata": {},
   "source": [
    "## tri·ªÉn khai RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5d333f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k√™ÃÅt quaÃâ cuÃâa: Danh s√°ch b√†n l√†m vi·ªác\n",
      "\n",
      "**Desks Boulerard**\n",
      "- Gi√°: 39.999.000 VNƒê\n",
      "- M√¥ t·∫£: Ph√π h·ª£p cho h·ªçc t·∫≠p, l√†m vi·ªác t·∫°i nh√† ho·∫∑c vƒÉn ph√≤ng.\n",
      "\n",
      "**Desks Cottage**\n",
      "- Gi√°: 379.999.000 VNƒê\n",
      "- M√¥ t·∫£: B√†n l√†m vi·ªác ƒëa nƒÉng, c√≥ ngƒÉn k√©o ti·ªán l·ª£i.\n",
      "\n",
      "**Desks Harper**\n",
      "- Gi√°: 100.000.000 VNƒê\n",
      "- M√¥ t·∫£: Ch·∫•t li·ªáu g·ªó c√¥ng nghi·ªáp b·ªÅn ƒë·∫πp, ch·ªëng ·∫©m m·ªëc.\n"
     ]
    }
   ],
   "source": [
    "# üìå C√¢u h·ªèi\n",
    "question = \"v√¢Ã£t li√™Ã£u laÃÄ giÃÄ?\"\n",
    "\n",
    "# üìå Search trong Milvus (ch·ªâ l·∫•y top 1)\n",
    "search_res = milvus_client.search(\n",
    "    collection_name=collection_name,\n",
    "    data=[emb_text(question)],\n",
    "    limit=1,  # üîπ Ch·ªâ l·∫•y 1 k·∫øt qu·∫£ t·ªët nh·∫•t\n",
    "    search_params={\"metric_type\": \"IP\", \"params\": {}},\n",
    "    output_fields=[\"text\"],\n",
    ")\n",
    "\n",
    "# üìå L·∫•y text t·ª´ k·∫øt qu·∫£\n",
    "best_text = search_res[0][0][\"entity\"][\"text\"]\n",
    "#best_distance = search_res[0][0][\"distance\"]\n",
    "\n",
    "print(\"k√™ÃÅt quaÃâ cuÃâa:\", best_text)\n",
    "#print(\"üìè ƒê·ªô t∆∞∆°ng ƒë·ªìng:\", best_distance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabafa6a",
   "metadata": {},
   "source": [
    "# Hybrid Search with Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab22020f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pymilvus version: 2.6.1\n",
      "langchain version: 0.3.27\n",
      "sentence_transformers version: 5.1.0\n"
     ]
    }
   ],
   "source": [
    "# Ki·ªÉm tra c√†i ƒë·∫∑t\n",
    "import pymilvus\n",
    "import langchain\n",
    "import sentence_transformers\n",
    "print(\"pymilvus version:\", pymilvus.__version__)\n",
    "print(\"langchain version:\", langchain.__version__)\n",
    "print(\"sentence_transformers version:\", sentence_transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54352310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da73a724b3148f39ff1f96c130776d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/444 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Big_project_2025\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in D:\\Big_project_2025\\models--BAAI--bge-m3. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d9c0c76998d4c80b8668de33fe0523b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82973cd77d164d4eac2d65f0a348a9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba50501848648fb91af5383b8f0efba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d88d780a72499cb7a6a5a7533c4bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94dcc37fc58a402f98d57d6ea95047ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/123 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50fe4aaa54be4aa7910e3c1f5e6714b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/687 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "768890a88ca04e2a952f362c96fb79d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de6606b324b4de4a8471a1f792dc574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d5084b97d740eca9da9481ef69dc64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".DS_Store:   0%|          | 0.00/6.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ddbab9fe3a4894b85f7bfdb0010a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "colbert_linear.pt:   0%|          | 0.00/2.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83efb9b6d71c4f14a2df310f46ba1e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "miracl.jpg:   0%|          | 0.00/576k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead9efd7175a41d78431230e1ebe565a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b930ebc6b943539ed0aa7308e3b8f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bm25.jpg:   0%|          | 0.00/132k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c2b2941c694775beec16065280fbcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mkqa.jpg:   0%|          | 0.00/608k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972dbaaecb81430ebc4bbc2f800d747c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "long.jpg:   0%|          | 0.00/485k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed63c516c49447e580661767ef4581f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "nqa.jpg:   0%|          | 0.00/158k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f5d7bb7c134fcd89f34ecedc250033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "others.webp:   0%|          | 0.00/21.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f8c196df7264440b600a6aa3bbc949d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "long.jpg:   0%|          | 0.00/127k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd648e69dd54a2a983874cfe21b9bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f31e60856c43518b93f920156c0c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Constant_7_attr__value:   0%|          | 0.00/65.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130e5857d272484a856683d37fbdedbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/model.onnx:   0%|          | 0.00/725k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7935b6fd414f4211b20cbab6e7c4b724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/698 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1f46a80c7040e68a8db3a05b40d3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/model.onnx_data:   0%|          | 0.00/2.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7403d550ddea47ceb5fb5c97dcc2a1fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af40c5f5e336405b9c66eec2443943ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d68e93c0d340e999d436d7516195f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0af89b3a1034a499cd6686a365f356c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787061a1ceac44caa4cad27fbea88dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704ef1c73111402bb3b6ad7f0d11bcf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377de4d0c6344c91bf69661620460884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sparse_linear.pt:   0%|          | 0.00/3.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "from pymilvus.model.hybrid import BGEM3EmbeddingFunction\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "import requests\n",
    "\n",
    "# K·∫øt n·ªëi Milvus\n",
    "connections.connect(\"default\", uri=\"http://localhost:19530\")\n",
    "collection_name = \"hybrid_search_SHOP\"\n",
    "\n",
    "# Kh·ªüi t·∫°o BGE-M3 (l∆∞u model ·ªü D:/Big_project_2025)\n",
    "if 'ef' not in globals():\n",
    "    ef = BGEM3EmbeddingFunction(model_name=\"BAAI/bge-m3\", use_fp16=False, device=\"cpu\", cache_dir=\"D:/Big_project_2025\")\n",
    "    dense_dim = ef.dim[\"dense\"]\n",
    "    use_hybrid = True\n",
    "    print(\"Kh·ªüi t·∫°o l·∫°i BGE-M3.\")\n",
    "else:\n",
    "    print(\"BGE-M3 ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o tr∆∞·ªõc ƒë√≥, kh√¥ng c·∫ßn ch·∫°y l·∫°i.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5333e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o schema collection\n",
    "fields = [ # Danh s√°ch c√°c tr∆∞·ªùng trong collection\n",
    "    FieldSchema(name=\"pk\", dtype=DataType.VARCHAR, is_primary=True, auto_id=True, max_length=100),\n",
    "    FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=8192),\n",
    "    FieldSchema(name=\"dense_vector\", dtype=DataType.FLOAT_VECTOR, dim=dense_dim),\n",
    "]\n",
    "if use_hybrid: # N·∫øu d√πng hybrid th√¨ th√™m tr∆∞·ªùng sparse_vector\n",
    "    fields.append(FieldSchema(name=\"sparse_vector\", dtype=DataType.SPARSE_FLOAT_VECTOR))\n",
    "schema = CollectionSchema(fields)\n",
    "\n",
    "# T·∫°o collection n·∫øu ch∆∞a t·ªìn t·∫°i\n",
    "if utility.has_collection(collection_name):\n",
    "    Collection(collection_name).drop()\n",
    "col = Collection(collection_name, schema)\n",
    "\n",
    "# T·∫°o index v√† load d·ªØ li·ªáu v√†o b·ªô nh·ªõ\n",
    "dense_index = {\"index_type\": \"AUTOINDEX\", \"metric_type\": \"IP\"}\n",
    "col.create_index(\"dense_vector\", dense_index)\n",
    "if use_hybrid: # N·∫øu d√πng hybrid th√¨ t·∫°o index cho sparse_vector\n",
    "    sparse_index = {\"index_type\": \"SPARSE_INVERTED_INDEX\", \"metric_type\": \"IP\"}\n",
    "    col.create_index(\"sparse_vector\", sparse_index)\n",
    "col.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e7d163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T·ªïng s·ªë chunks: 13\n"
     ]
    }
   ],
   "source": [
    "# ƒê∆∞·ªùng d·∫´n data\n",
    "data_folder = r\"D:\\Big_project_2025\\RAG_Milvus\\data_Shop\"\n",
    "\n",
    "# ƒê·ªçc v√† x·ª≠ l√Ω data t·ª´ folder\n",
    "docs = []\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=50) # C·∫Øt ƒëo·∫°n vƒÉn b·∫£n th√†nh c√°c chunks nh·ªè h∆°n\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith(\".md\"):\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "            chunks = splitter.split_text(text)\n",
    "            docs.extend(chunks)\n",
    "\n",
    "print(f\"T·ªïng s·ªë chunks: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7f1ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 0 entities.\n"
     ]
    }
   ],
   "source": [
    "# T·∫°o embeddings\n",
    "docs_embeddings = ef(docs)\n",
    "\n",
    "# Ch√®n v√†o Milvus (batch) v·ªõi chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu ph√π h·ª£p\n",
    "batch_size = 50\n",
    "for i in range(0, len(docs), batch_size):\n",
    "    batched_docs = docs[i:i + batch_size]\n",
    "    batched_dense = docs_embeddings[\"dense\"][i:i + batch_size]\n",
    "    batched_sparse = docs_embeddings[\"sparse\"][i:i + batch_size]\n",
    "\n",
    "    # Chuy·ªÉn dense sang list (n·∫øu c·∫ßn)\n",
    "    batched_dense_converted = [vec.tolist() for vec in batched_dense]\n",
    "\n",
    "    # Chuy·ªÉn sparse sang ƒë·ªãnh d·∫°ng dict {index: value} cho SPARSE_FLOAT_VECTOR\n",
    "    batched_sparse_converted = []\n",
    "    for sparse_vec in batched_sparse:\n",
    "        coo = sparse_vec.tocoo()  # Chuy·ªÉn sang COO format ƒë·ªÉ l·∫•y index v√† value\n",
    "        sparse_dict = {int(idx): float(val) for idx, val in zip(coo.col, coo.data)}\n",
    "        batched_sparse_converted.append(sparse_dict)\n",
    "\n",
    "    # Th·ª© t·ª± ch√®n ph·∫£i kh·ªõp schema: text, dense_vector, sparse_vector (n·∫øu hybrid)\n",
    "    batched_entities = [\n",
    "        batched_docs,  # text\n",
    "        batched_dense_converted,  # dense_vector\n",
    "    ]\n",
    "    if use_hybrid:\n",
    "        batched_entities.append(batched_sparse_converted)  # sparse_vector (th√™m sau dense)\n",
    "\n",
    "    col.insert(batched_entities)\n",
    "\n",
    "print(f\"Inserted {col.num_entities} entities.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3937351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import AnnSearchRequest, WeightedRanker\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "def search(query, limit=5, sparse_weight=0.7, dense_weight=1.0):\n",
    "    query_emb = ef([query])\n",
    "    \n",
    "    # Chuy·ªÉn ƒë·ªïi dense vector sang list\n",
    "    dense_vec = query_emb[\"dense\"][0].tolist()\n",
    "    \n",
    "    # Chuy·ªÉn ƒë·ªïi sparse vector sang dict {index: value}\n",
    "    sparse_vec = query_emb[\"sparse\"][0]\n",
    "    if issparse(sparse_vec):\n",
    "        coo = sparse_vec.tocoo()\n",
    "        sparse_dict = {int(idx): float(val) for idx, val in zip(coo.col, coo.data)}\n",
    "    else:\n",
    "        sparse_dict = sparse_vec  # N·∫øu ƒë√£ ·ªü ƒë·ªãnh d·∫°ng dict\n",
    "    \n",
    "    # T·∫°o search requests\n",
    "    dense_req = AnnSearchRequest([dense_vec], \"dense_vector\", {\"metric_type\": \"IP\"}, limit=limit)\n",
    "    sparse_req = AnnSearchRequest([sparse_dict], \"sparse_vector\", {\"metric_type\": \"IP\"}, limit=limit)\n",
    "    \n",
    "    # Th·ª±c hi·ªán hybrid search v·ªõi reranking\n",
    "    rerank = WeightedRanker(sparse_weight, dense_weight)\n",
    "    res = col.hybrid_search([sparse_req, dense_req], rerank=rerank, limit=limit, output_fields=[\"text\"])[0]\n",
    "    return [hit.get(\"text\") for hit in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ed4560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def generate_answer(query, retrieved_docs):\n",
    "    context = \"\\n\".join(retrieved_docs)\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"B·∫°n l√† chatbot b√°n h√†ng ti·∫øng Vi·ªát. D·ª±a tr√™n th√¥ng tin sau ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi: {query}\\n\\nContext: {context}\\n\\nTr·∫£ l·ªùi h·ªØu √≠ch, ng·∫Øn g·ªçn b·∫±ng ti·∫øng Vi·ªát.\"\n",
    "    ).format(query=query, context=context)\n",
    "    \n",
    "    # G·ªçi API xAI v·ªõi key c·ªßa b·∫°n\n",
    "    api_url = \"https://api.x.ai/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer xai-GM5dDZHsyHVeue72pFibiLpeTHLuvJHlmRk356y4H8WLU83bNdfrUICGT9LAFRFryiaerfVgyLVCKNlF\"\n",
    "    }\n",
    "    data = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a test assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"model\": \"grok-4-latest\",\n",
    "        \"stream\": False,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(api_url, headers=headers, json=data, timeout=30)\n",
    "        response.raise_for_status()  # Ki·ªÉm tra l·ªói HTTP\n",
    "        result = response.json()\n",
    "        return result[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"L·ªói khi g·ªçi API: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefd8ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['# Ch√≠nh s√°ch b·∫£o h√†nh\\n\\n## Th·ªùi gian b·∫£o h√†nh\\n- T·∫•t c·∫£ s·∫£n ph·∫©m: 12 th√°ng k·ªÉ t·ª´ ng√†y mua.\\n- M·ªôt s·ªë s·∫£n ph·∫©m sofa cao c·∫•p: 24 th√°ng.\\n\\n## ƒêi·ªÅu ki·ªán b·∫£o h√†nh\\n- S·∫£n ph·∫©m b·ªã l·ªói do nh√† s·∫£n xu·∫•t.\\n- C√≤n phi·∫øu b·∫£o h√†nh ho·∫∑c h√≥a ƒë∆°n mua h√†ng.\\n\\n## Kh√¥ng √°p d·ª•ng b·∫£o h√†nh\\n- H∆∞ h·ªèng do s·ª≠ d·ª•ng sai c√°ch (·∫©m m·ªëc, va ƒë·∫≠p, ch√°y x∆∞·ªõc).\\n- S·∫£n ph·∫©m b·ªã s·ª≠a ch·ªØa ·ªü n∆°i kh√°c.\\n- Qu√° th·ªùi h·∫°n b·∫£o h√†nh.\\n\\n## H·ªó tr·ª£ sau b·∫£o h√†nh\\n- C√≥ d·ªãch v·ª• s·ª≠a ch·ªØa, thay m·ªõi v·ªõi gi√° ∆∞u ƒë√£i.\\n- H·ªó tr·ª£ t∆∞ v·∫•n mi·ªÖn ph√≠ qua hotline.', '# Th√¥ng tin c·ª≠a h√†ng\\n\\nC·ª≠a h√†ng N·ªôi Th·∫•t PT chuy√™n cung c·∫•p sofa, b√†n ƒÉn, b√†n l√†m vi·ªác v√† c√°c s·∫£n ph·∫©m n·ªôi th·∫•t cao c·∫•p.\\n\\n- ƒê·ªãa ch·ªâ: 256 Nguy·ªÖn VƒÉn C·ª´, An H√≤a, Ninh Ki·ªÅu, C·∫ßn Th∆°\\n- Hotline: 0292-3894050\\n- Email: turnthuan1@gmail.com\\n- Fanpage: https://github.com/phithuan/AI_Challenge_2025\\n\\nCam k·∫øt:\\n- S·∫£n ph·∫©m ch√≠nh h√£ng, ch·∫•t l∆∞·ª£ng cao.\\n- Gi√° c·∫£ minh b·∫°ch, c·∫°nh tranh.\\n- B·∫£o h√†nh 12 th√°ng to√†n qu·ªëc.\\n- H·ªó tr·ª£ kh√°ch h√†ng nhanh ch√≥ng, t·∫≠n t√¢m.', '# Danh s√°ch Sofa\\n\\n## Sofa CAPTTI\\n- Gi√°: 2.000.000 VNƒê\\n- M√¥ t·∫£: Sofa v·∫£i n·ªâ cao c·∫•p, √™m √°i v√† d·ªÖ v·ªá sinh.\\n\\n## Sofa GINEVRA\\n- Gi√°: 4.300.000 VNƒê\\n- M√¥ t·∫£: Thi·∫øt k·∫ø hi·ªán ƒë·∫°i, ph√π h·ª£p v·ªõi m·ªçi kh√¥ng gian ph√≤ng kh√°ch.\\n\\n## Sofa Best View\\n- Gi√°: 15.000.000 VNƒê\\n- M√¥ t·∫£: Khung g·ªó t·ª± nhi√™n ch·∫Øc ch·∫Øn, b·ªÅn b·ªâ theo th·ªùi gian.\\n\\n## Sofa Quen\\n- Gi√°: 9.100.000 VNƒê\\n- M√¥ t·∫£: ƒê·ªám m√∫t d√†y d·∫∑n, mang l·∫°i c·∫£m gi√°c tho·∫£i m√°i t·ªëi ƒëa.\\n\\n## Sofa King\\n- Gi√°: 19.000.000 VNƒê\\n- M√¥ t·∫£: ƒê·ªám m√∫t d√†y d·∫∑n, mang l·∫°i c·∫£m gi√°c tho·∫£i m√°i t·ªëi ƒëa.', '## Sofa ESPED Fix\\n- Gi√°: 8.600.000 VNƒê\\n- M√¥ t·∫£: Sofa v·∫£i n·ªâ cao c·∫•p, √™m √°i v√† d·ªÖ v·ªá sinh.', '# Danh s√°ch b√†n ƒÉn\\n\\n## Canadel Downtown 72\" Glass Dining Table\\n- Gi√°: 199.988.000 VNƒê\\n- M√¥ t·∫£: B·ªÅ m·∫∑t ph·ªß s∆°n ch·ªëng tr·∫ßy, d·ªÖ lau ch√πi khi s·ª≠ d·ª•ng.\\n\\n## Carolina Dining Table\\n- Gi√°: 89.000.000 VNƒê\\n- M√¥ t·∫£: B·ªÅ m·∫∑t ph·ªß s∆°n ch·ªëng tr·∫ßy, d·ªÖ lau ch√πi khi s·ª≠ d·ª•ng.\\n\\n## Caden 6pc Dining Set\\n- Gi√°: 680.000.000 VNƒê\\n- M√¥ t·∫£: B√†n ƒÉn g·ªó s·ªìi, phong c√°ch t·ªëi gi·∫£n, sang tr·ªçng.']\n"
     ]
    }
   ],
   "source": [
    "result = search(\"giaÃÅ sofa\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3e1644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot s·∫µn s√†ng! Nh·∫≠p 'exit' ƒë·ªÉ tho√°t\n",
      "Tr·∫£ l·ªùi: L·ªói khi g·ªçi API: 403 Client Error: Forbidden for url: https://api.x.ai/v1/chat/completions\n"
     ]
    }
   ],
   "source": [
    "# Chatbot loop\n",
    "print(\"Chatbot s·∫µn s√†ng! Nh·∫≠p 'exit' ƒë·ªÉ tho√°t\")\n",
    "while True:\n",
    "    query = input(\"C√¢u h·ªèi c·ªßa b·∫°n: \")\n",
    "    if query.lower() == \"exit\":\n",
    "        break\n",
    "    retrieved = search(query)\n",
    "    if not retrieved:  # Ki·ªÉm tra n·∫øu kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£\n",
    "        print(\"Tr·∫£ l·ªùi: Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p.\")\n",
    "    else:\n",
    "        answer = generate_answer(query, retrieved)\n",
    "        print(\"Tr·∫£ l·ªùi:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d81518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
