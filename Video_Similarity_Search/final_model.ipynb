{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8e26429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Big_project_2025\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.1 at schema.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Big_project_2025\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.1 at common.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Big_project_2025\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.1 at milvus.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Big_project_2025\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.1 at rg.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Big_project_2025\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.1 at feder.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "d:\\Big_project_2025\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.1 at msg.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from pymilvus import MilvusClient\n",
    "\n",
    "# ================== Config ==================\n",
    "DB_PARAMS = {\n",
    "    \"dbname\": \"video_frame\",   # database ƒë√£ t·∫°o\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"123\",         # ƒë·ªïi theo m·∫≠t kh·∫©u c·ªßa b·∫°n\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\"\n",
    "}\n",
    "\n",
    "CSV_DIR   = r\"D:\\Big_project_2025\\Video_Similarity_Search\\data\\csv\"\n",
    "FRAME_DIR = r\"D:\\Big_project_2025\\Video_Similarity_Search\\data\\key_frame\"\n",
    "VIDEO_DIR = r\"D:\\Big_project_2025\\Video_Similarity_Search\\data\\video\"\n",
    "MODEL_DIR = r\"D:\\Big_project_2025\\huggingface_cache\"  # n∆°i l∆∞u model CLIP\n",
    "\n",
    "# ================== K·∫øt n·ªëi DB + Milvus ==================s\n",
    "conn = psycopg2.connect(**DB_PARAMS)\n",
    "cur = conn.cursor()\n",
    "client = MilvusClient(uri=\"http://localhost:19530\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf292d6",
   "metadata": {},
   "source": [
    "# Cell 2. T·∫°o b·∫£ng PostgreSQL (ch·∫°y 1 l·∫ßn)\n",
    "chaÃ£y b√™n pg admin r√¥ÃÄi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e94983",
   "metadata": {},
   "source": [
    "# Cell 3 ‚Äì T·∫°o collection Milvus (ch·∫°y 1 l·∫ßn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d520435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Danh s√°ch collection: ['video_search', 'image_collection', 'text_image_video_collection', 'Movies', 'my_rag_collection']\n"
     ]
    }
   ],
   "source": [
    "# K·∫øt n·ªëi Milvus\n",
    "milvus_client = MilvusClient(uri=\"http://localhost:19530\")\n",
    "\n",
    "# T√™n collection\n",
    "collection_name = \"text_image_video_collection\"\n",
    "\n",
    "# X√≥a collection c≈© (n·∫øu c√≥) -> kh·ªüi t·∫°o l·∫°i t·ª´ ƒë·∫ßu\n",
    "if milvus_client.has_collection(collection_name):\n",
    "    milvus_client.drop_collection(collection_name)\n",
    "    print(f\"‚ö†Ô∏è Collection '{collection_name}' ƒë√£ b·ªã x√≥a\")\n",
    "\n",
    "# T·∫°o collection m·ªõi\n",
    "milvus_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    dimension=512,              # Vector size c·ªßa CLIP ViT-B/32\n",
    "    auto_id=True,               # T·ª± ƒë·ªông t·∫°o ID\n",
    "    enable_dynamic_field=True   # Cho ph√©p th√™m field ƒë·ªông (vd: frame_path)\n",
    ")\n",
    "\n",
    "# Ki·ªÉm tra danh s√°ch collection hi·ªán c√≥\n",
    "collections = milvus_client.list_collections()\n",
    "print(\"‚úÖ Danh s√°ch collection:\", collections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12190930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'collection_name': 'text_image_video_collection',\n",
       " 'auto_id': True,\n",
       " 'num_shards': 1,\n",
       " 'description': '',\n",
       " 'fields': [{'field_id': 100,\n",
       "   'name': 'id',\n",
       "   'description': '',\n",
       "   'type': <DataType.INT64: 5>,\n",
       "   'params': {},\n",
       "   'auto_id': True,\n",
       "   'is_primary': True},\n",
       "  {'field_id': 101,\n",
       "   'name': 'vector',\n",
       "   'description': '',\n",
       "   'type': <DataType.FLOAT_VECTOR: 101>,\n",
       "   'params': {'dim': 512}}],\n",
       " 'functions': [],\n",
       " 'aliases': [],\n",
       " 'collection_id': 460239432247376457,\n",
       " 'consistency_level': 2,\n",
       " 'properties': {},\n",
       " 'num_partitions': 1,\n",
       " 'enable_dynamic_field': True,\n",
       " 'created_timestamp': 460240111572615174}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# M√¥ t·∫£ B·ªô s∆∞u t·∫≠p\n",
    "res = client.describe_collection(\n",
    "    collection_name=\"text_image_video_collection\"\n",
    ")\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6f8dfc",
   "metadata": {},
   "source": [
    "# Cell 4 ‚Äì Load CLIP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b365fc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import CLIPModel, CLIPProcessor\n",
    "\n",
    "# X√°c ƒë·ªãnh thi·∫øt b·ªã s·ª≠ d·ª•ng: ∆∞u ti√™n GPU (cuda) n·∫øu c√≥, n·∫øu kh√¥ng th√¨ d√πng CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# T·∫£i m√¥ h√¨nh CLIP ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán tr∆∞·ªõc t·ª´ Hugging Face, l∆∞u tr·ªØ t·∫°i th∆∞ m·ª•c MODEL_DIR\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\", cache_dir=MODEL_DIR).to(device)\n",
    "\n",
    "# T·∫£i b·ªô x·ª≠ l√Ω (processor) c·ªßa CLIP ƒë·ªÉ chu·∫©n b·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o (h√¨nh ·∫£nh, vƒÉn b·∫£n)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\", cache_dir=MODEL_DIR)\n",
    "\n",
    "def encode_image(image_path):\n",
    "    \"\"\"\n",
    "    H√†m m√£ h√≥a h√¨nh ·∫£nh th√†nh vector ƒë·∫∑c tr∆∞ng s·ª≠ d·ª•ng m√¥ h√¨nh CLIP.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): ƒê∆∞·ªùng d·∫´n t·ªõi file h√¨nh ·∫£nh c·∫ßn m√£ h√≥a.\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Vector ƒë·∫∑c tr∆∞ng c·ªßa h√¨nh ·∫£nh ho·∫∑c None n·∫øu c√≥ l·ªói.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # M·ªü file h√¨nh ·∫£nh b·∫±ng PIL\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # Ti·ªÅn x·ª≠ l√Ω h√¨nh ·∫£nh: chuy·ªÉn ƒë·ªïi ƒë·ªãnh d·∫°ng, chu·∫©n h√≥a, v√† ƒë∆∞a v√†o tensor PyTorch\n",
    "        inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        # T·∫Øt t√≠nh to√°n gradient ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô v√† gi·∫£m s·ª≠ d·ª•ng b·ªô nh·ªõ\n",
    "        with torch.no_grad():\n",
    "            # L·∫•y vector ƒë·∫∑c tr∆∞ng c·ªßa h√¨nh ·∫£nh t·ª´ m√¥ h√¨nh CLIP\n",
    "            image_features = model.get_image_features(**inputs)\n",
    "        \n",
    "        # Chuy·ªÉn vector ƒë·∫∑c tr∆∞ng t·ª´ tensor v·ªÅ m·∫£ng numpy v√† tr·∫£ v·ªÅ\n",
    "        return image_features[0].cpu().numpy()\n",
    "    \n",
    "    except Exception as e:\n",
    "        # In th√¥ng b√°o l·ªói n·∫øu qu√° tr√¨nh x·ª≠ l√Ω h√¨nh ·∫£nh th·∫•t b·∫°i\n",
    "        print(f\"L·ªói khi x·ª≠ l√Ω {image_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f3151d",
   "metadata": {},
   "source": [
    "# Cell 5 ‚Äì H√†m insert t√°ch ri√™ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf260fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def insert_to_milvus(frame_path, emb):\n",
    "    \"\"\"\n",
    "    Ch√®n vector ƒë·∫∑c tr∆∞ng v√† ƒë∆∞·ªùng d·∫´n frame v√†o collection trong Milvus.\n",
    "\n",
    "    Args:\n",
    "        frame_path (str): ƒê∆∞·ªùng d·∫´n t·ªõi file frame (h√¨nh ·∫£nh).\n",
    "        emb (numpy.ndarray): Vector ƒë·∫∑c tr∆∞ng c·ªßa frame (th∆∞·ªùng t·ª´ m√¥ h√¨nh nh∆∞ CLIP).\n",
    "\n",
    "    Returns:\n",
    "        str: ID c·ªßa b·∫£n ghi v·ª´a ch√®n trong Milvus.\n",
    "    \"\"\"\n",
    "    # S·ª≠ d·ª•ng client c·ªßa Milvus ƒë·ªÉ ch√®n d·ªØ li·ªáu v√†o collection c√≥ t√™n \"text_image_video_collection\"\n",
    "    res = client.insert(\n",
    "        collection_name=\"text_image_video_collection\",\n",
    "        data=[{\"vector\": emb, \"frame_path\": frame_path}]\n",
    "    )\n",
    "    # Tr·∫£ v·ªÅ ID ƒë·∫ßu ti√™n c·ªßa b·∫£n ghi v·ª´a ch√®n\n",
    "    return res[\"ids\"][0]\n",
    "\n",
    "\n",
    "def insert_to_postgres(video_id, frame_path, pts_time, frame_idx, fps, milvus_id):\n",
    "    \"\"\"\n",
    "    Ch√®n th√¥ng tin frame v√†o b·∫£ng frame_mappings trong PostgreSQL.\n",
    "\n",
    "    Args:\n",
    "        video_id (str): ID c·ªßa video ch·ª©a frame.\n",
    "        frame_path (str): ƒê∆∞·ªùng d·∫´n t·ªõi file frame.\n",
    "        pts_time (float): Th·ªùi gian tr√¨nh b√†y (presentation timestamp) c·ªßa frame trong video.\n",
    "        frame_idx (int): Ch·ªâ s·ªë c·ªßa frame trong video.\n",
    "        fps (float): T·ªëc ƒë·ªô khung h√¨nh (frames per second) c·ªßa video.\n",
    "        milvus_id (str): ID c·ªßa b·∫£n ghi t∆∞∆°ng ·ª©ng trong Milvus.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Th·ª±c hi·ªán c√¢u l·ªánh SQL ƒë·ªÉ ch√®n d·ªØ li·ªáu v√†o b·∫£ng frame_mappings\n",
    "    cur.execute(\"\"\"\n",
    "        INSERT INTO frame_mappings (video_id, frame_path, pts_time, frame_idx, fps, milvus_id)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "        ON CONFLICT (frame_path) DO NOTHING\n",
    "    \"\"\", (video_id, frame_path, pts_time, frame_idx, fps, milvus_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc72ee0",
   "metadata": {},
   "source": [
    "# Cell 6 ‚Äì Index to√†n b·ªô video (d√πng khi m·ªõi ch·∫°y l·∫ßn ƒë·∫ßu ho·∫∑c re-index)\n",
    "- Pipeline n√†y x√¢y d·ª±ng c∆° s·ªü d·ªØ li·ªáu cho h·ªá th·ªëng t√¨m ki·∫øm video d·ª±a tr√™n n·ªôi dung h√¨nh ·∫£nh.\n",
    "- Milvus l∆∞u vector ƒë·ªÉ t√¨m ki·∫øm t∆∞∆°ng ƒë·ªìng (similarity search).\n",
    "- PostgreSQL l∆∞u metadata ƒë·ªÉ truy v·∫•n th√¥ng tin chi ti·∫øt (v√≠ d·ª•: l·∫•y frame t·∫°i th·ªùi ƒëi·ªÉm c·ª• th·ªÉ trong video)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c60c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Indexed L21_V001\n",
      "‚úÖ Indexed L21_V002\n",
      "‚úÖ Indexed L21_V003\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ================== Cell 6: Index d·ªØ li·ªáu ==================\n",
    "def insert_to_milvus(frame_path, emb):\n",
    "    \"\"\"\n",
    "    Ch√®n vector ƒë·∫∑c tr∆∞ng v√† ƒë∆∞·ªùng d·∫´n frame v√†o collection Milvus.\n",
    "\n",
    "    Args:\n",
    "        frame_path (str): ƒê∆∞·ªùng d·∫´n t·ªõi file frame (h√¨nh ·∫£nh).\n",
    "        emb (numpy.ndarray): Vector ƒë·∫∑c tr∆∞ng c·ªßa frame t·ª´ m√¥ h√¨nh CLIP.\n",
    "\n",
    "    Returns:\n",
    "        str or None: ID c·ªßa b·∫£n ghi trong Milvus ho·∫∑c None n·∫øu l·ªói.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # G·ªçi API client c·ªßa Milvus ƒë·ªÉ ch√®n d·ªØ li·ªáu v√†o collection \"text_image_video_collection\"\n",
    "        # D·ªØ li·ªáu l√† m·ªôt danh s√°ch ch·ª©a dictionary v·ªõi hai tr∆∞·ªùng: vector (ƒë·∫∑c tr∆∞ng) v√† frame_path\n",
    "        res = client.insert(\n",
    "            collection_name=\"text_image_video_collection\",\n",
    "            data=[{\"vector\": emb, \"frame_path\": frame_path}]\n",
    "        )\n",
    "        # Ki·ªÉm tra k·∫øt qu·∫£ tr·∫£ v·ªÅ: Milvus v2 tr·∫£ v·ªÅ dict v·ªõi tr∆∞·ªùng \"ids\" ch·ª©a danh s√°ch ID\n",
    "        # L·∫•y ID ƒë·∫ßu ti√™n n·∫øu t·ªìn t·∫°i, n·∫øu kh√¥ng tr·∫£ v·ªÅ None\n",
    "        return res[\"ids\"][0] if \"ids\" in res and len(res[\"ids\"]) > 0 else None\n",
    "    except Exception as e:\n",
    "        # In l·ªói chi ti·∫øt n·∫øu ch√®n th·∫•t b·∫°i (v√≠ d·ª•: k·∫øt n·ªëi Milvus l·ªói, schema kh√¥ng kh·ªõp)\n",
    "        print(f\"‚ùå L·ªói insert Milvus cho {frame_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def insert_to_postgres(video_id, frame_path, pts_time, frame_idx, fps, milvus_id):\n",
    "    \"\"\"\n",
    "    Ch√®n metadata c·ªßa frame v√†o b·∫£ng frame_mappings trong PostgreSQL.\n",
    "\n",
    "    Args:\n",
    "        video_id (str): ID c·ªßa video ch·ª©a frame.\n",
    "        frame_path (str): ƒê∆∞·ªùng d·∫´n t·ªõi file frame.\n",
    "        pts_time (float): Th·ªùi gian tr√¨nh b√†y (presentation timestamp) c·ªßa frame.\n",
    "        frame_idx (int): Ch·ªâ s·ªë th·ª© t·ª± c·ªßa frame trong video.\n",
    "        fps (float): T·ªëc ƒë·ªô khung h√¨nh c·ªßa video.\n",
    "        milvus_id (str): ID c·ªßa b·∫£n ghi t∆∞∆°ng ·ª©ng trong Milvus.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Th·ª±c hi·ªán c√¢u l·ªánh SQL INSERT ƒë·ªÉ th√™m b·∫£n ghi v√†o b·∫£ng frame_mappings\n",
    "        # ON CONFLICT (frame_path) DO NOTHING: B·ªè qua n·∫øu frame_path ƒë√£ t·ªìn t·∫°i\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO frame_mappings (video_id, frame_path, pts_time, frame_idx, fps, milvus_id)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s)\n",
    "            ON CONFLICT (frame_path) DO NOTHING\n",
    "        \"\"\", (video_id, frame_path, pts_time, frame_idx, fps, milvus_id))\n",
    "    except Exception as e:\n",
    "        # In l·ªói n·∫øu ch√®n th·∫•t b·∫°i (v√≠ d·ª•: k·∫øt n·ªëi DB l·ªói, ki·ªÉu d·ªØ li·ªáu kh√¥ng kh·ªõp)\n",
    "        print(f\"‚ùå L·ªói insert Postgres cho {frame_path}: {e}\")\n",
    "\n",
    "def index_videos():\n",
    "    \"\"\"\n",
    "    Pipeline l·∫≠p ch·ªâ m·ª•c video: m√£ h√≥a frame, l∆∞u vector v√†o Milvus v√† metadata v√†o PostgreSQL.\n",
    "    Duy·ªát qua t·∫•t c·∫£ video trong th∆∞ m·ª•c VIDEO_DIR, x·ª≠ l√Ω frame v√† file CSV t∆∞∆°ng ·ª©ng.\n",
    "    \"\"\"\n",
    "    # Duy·ªát qua c√°c th∆∞ m·ª•c con trong FRAME_DIR (m·ªói th∆∞ m·ª•c ch·ª©a frame c·ªßa m·ªôt video)\n",
    "    for key_frame_dir in os.listdir(FRAME_DIR):\n",
    "        # T·∫°o ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß t·ªõi th∆∞ m·ª•c frame, file CSV v√† video\n",
    "        frame_dir_path = os.path.join(FRAME_DIR, key_frame_dir)\n",
    "        csv_path = os.path.join(CSV_DIR, f\"{key_frame_dir}.csv\")\n",
    "        video_path = os.path.join(VIDEO_DIR, f\"{key_frame_dir}.mp4\")\n",
    "\n",
    "        # Ki·ªÉm tra s·ª± t·ªìn t·∫°i c·ªßa th∆∞ m·ª•c frame, file video v√† file CSV\n",
    "        if not (os.path.isdir(frame_dir_path) and os.path.exists(video_path) and os.path.exists(csv_path)):\n",
    "            print(f\"‚ö†Ô∏è Thi·∫øu file cho {key_frame_dir}, b·ªè qua.\")\n",
    "            continue\n",
    "\n",
    "        # ƒê·ªçc file CSV ch·ª©a th√¥ng tin mapping (pts_time, fps) c·ªßa frame\n",
    "        mapping_df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Ch√®n th√¥ng tin video v√†o b·∫£ng videos ho·∫∑c l·∫•y video_id n·∫øu video ƒë√£ t·ªìn t·∫°i\n",
    "        # ƒê·∫£m b·∫£o ƒë∆∞·ªùng d·∫´n s·ª≠ d·ª•ng d·∫•u \"/\" ƒë·ªÉ t∆∞∆°ng th√≠ch ƒëa n·ªÅn t·∫£ng\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO videos (video_path, title, description)\n",
    "            VALUES (%s, %s, %s)\n",
    "            ON CONFLICT (video_path) DO NOTHING\n",
    "            RETURNING id\n",
    "        \"\"\", (video_path.replace(\"\\\\\", \"/\"), os.path.basename(video_path), \"Video demo\"))\n",
    "        \n",
    "        # L·∫•y k·∫øt qu·∫£ c·ªßa c√¢u INSERT (row ch·ª©a video_id n·∫øu insert th√†nh c√¥ng)\n",
    "        row = cur.fetchone()\n",
    "        if row:\n",
    "            video_id = row[0]  # Video m·ªõi ƒë∆∞·ª£c ch√®n, l·∫•y video_id\n",
    "        else:\n",
    "            # N·∫øu video ƒë√£ t·ªìn t·∫°i (kh√¥ng insert), truy v·∫•n ƒë·ªÉ l·∫•y video_id\n",
    "            cur.execute(\"SELECT id FROM videos WHERE video_path=%s\", (video_path.replace(\"\\\\\", \"/\"),))\n",
    "            row = cur.fetchone()\n",
    "            if row:\n",
    "                video_id = row[0]  # L·∫•y video_id t·ª´ b·∫£n ghi hi·ªán c√≥\n",
    "            else:\n",
    "                print(f\"‚ùå Kh√¥ng t√¨m th·∫•y video {video_path}, b·ªè qua.\")\n",
    "                continue\n",
    "\n",
    "        # Duy·ªát t·ª´ng file trong th∆∞ m·ª•c frame\n",
    "        for frame_file in os.listdir(frame_dir_path):\n",
    "            # Ch·ªâ x·ª≠ l√Ω c√°c file h√¨nh ·∫£nh (.jpg, .jpeg, .png)\n",
    "            if not frame_file.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                continue\n",
    "            # T·∫°o ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß t·ªõi frame, ƒë·∫£m b·∫£o d√πng d·∫•u \"/\"\n",
    "            frame_path = os.path.join(frame_dir_path, frame_file).replace(\"\\\\\", \"/\")\n",
    "\n",
    "            # Tr√≠ch xu·∫•t ch·ªâ s·ªë frame t·ª´ t√™n file (ph·∫ßn tr∆∞·ªõc ƒëu√¥i m·ªü r·ªông)\n",
    "            try:\n",
    "                frame_idx = int(os.path.splitext(frame_file)[0])\n",
    "            except ValueError:\n",
    "                # B·ªè qua n·∫øu t√™n file kh√¥ng chuy·ªÉn ƒë∆∞·ª£c th√†nh s·ªë (frame_idx)\n",
    "                continue\n",
    "\n",
    "            # L·∫•y th√¥ng tin mapping t·ª´ file CSV d·ª±a tr√™n frame_idx\n",
    "            row = mapping_df[mapping_df[\"n\"] == frame_idx]\n",
    "            if row.empty:\n",
    "                # B·ªè qua n·∫øu kh√¥ng t√¨m th·∫•y th√¥ng tin mapping cho frame_idx\n",
    "                continue\n",
    "\n",
    "            # L·∫•y pts_time (th·ªùi gian frame) v√† fps t·ª´ file CSV\n",
    "            pts_time = float(row[\"pts_time\"].values[0])\n",
    "            fps = int(row[\"fps\"].values[0])\n",
    "\n",
    "            # M√£ h√≥a frame th√†nh vector ƒë·∫∑c tr∆∞ng b·∫±ng h√†m encode_image (d√πng CLIP)\n",
    "            emb = encode_image(frame_path)\n",
    "            if emb is None:\n",
    "                # B·ªè qua n·∫øu m√£ h√≥a frame th·∫•t b·∫°i\n",
    "                continue\n",
    "\n",
    "            # Ch√®n vector ƒë·∫∑c tr∆∞ng v√†o Milvus v√† l·∫•y milvus_id\n",
    "            milvus_id = insert_to_milvus(frame_path, emb)\n",
    "            if milvus_id is None:\n",
    "                # B·ªè qua n·∫øu ch√®n v√†o Milvus th·∫•t b·∫°i\n",
    "                continue\n",
    "\n",
    "            # Ch√®n metadata c·ªßa frame v√†o PostgreSQL\n",
    "            insert_to_postgres(video_id, frame_path, pts_time, frame_idx, fps, milvus_id)\n",
    "\n",
    "        # Commit giao d·ªãch PostgreSQL sau khi x·ª≠ l√Ω xong m·ªói video\n",
    "        conn.commit()\n",
    "        print(f\"‚úÖ Indexed {key_frame_dir}\")\n",
    "\n",
    "# ================== Ch·∫°y index ==================\n",
    "# G·ªçi h√†m ƒë·ªÉ b·∫Øt ƒë·∫ßu pipeline l·∫≠p ch·ªâ m·ª•c video\n",
    "index_videos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daf528b",
   "metadata": {},
   "source": [
    "# Cell 7 ‚Äì Index incremental (ch·ªâ data m·ªõi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff292ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_new_data():\n",
    "    for key_frame_dir in os.listdir(FRAME_DIR):\n",
    "        frame_dir_path = os.path.join(FRAME_DIR, key_frame_dir)\n",
    "        csv_path = os.path.join(CSV_DIR, f\"{key_frame_dir}.csv\")\n",
    "        video_path = os.path.join(VIDEO_DIR, f\"{key_frame_dir}.mp4\")\n",
    "\n",
    "        if not (os.path.isdir(frame_dir_path) and os.path.exists(video_path) and os.path.exists(csv_path)):\n",
    "            continue\n",
    "\n",
    "        mapping_df = pd.read_csv(csv_path)\n",
    "\n",
    "        # L·∫•y video_id\n",
    "        cur.execute(\"SELECT id FROM videos WHERE video_path=%s\", (video_path,))\n",
    "        video_id = cur.fetchone()\n",
    "        if not video_id:\n",
    "            continue\n",
    "        video_id = video_id[0]\n",
    "\n",
    "        # Check frame m·ªõi\n",
    "        for frame_file in os.listdir(frame_dir_path):\n",
    "            if not frame_file.endswith((\".jpg\",\".jpeg\",\".png\")):\n",
    "                continue\n",
    "            frame_path = os.path.join(frame_dir_path, frame_file).replace(\"\\\\\",\"/\")\n",
    "\n",
    "            cur.execute(\"SELECT 1 FROM frame_mappings WHERE frame_path=%s\", (frame_path,))\n",
    "            if cur.fetchone():  # ƒë√£ c√≥ th√¨ b·ªè qua\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                frame_idx = int(os.path.splitext(frame_file)[0])\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            row = mapping_df[mapping_df[\"n\"] == frame_idx]\n",
    "            if row.empty:\n",
    "                continue\n",
    "\n",
    "            pts_time = float(row[\"pts_time\"].values[0])\n",
    "            fps = int(row[\"fps\"].values[0])\n",
    "\n",
    "            # Encode\n",
    "            emb = encode_image(frame_path)\n",
    "            if emb is None:\n",
    "                continue\n",
    "\n",
    "            # Insert Milvus + Postgres\n",
    "            milvus_id = insert_to_milvus(frame_path, emb)\n",
    "            insert_to_postgres(video_id, frame_path, pts_time, frame_idx, fps, milvus_id)\n",
    "\n",
    "        conn.commit()\n",
    "        print(f\"‚úÖ Indexed new frames for {key_frame_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92630bc",
   "metadata": {},
   "source": [
    "# V·ªõi c·∫•u tr√∫c n√†y b·∫°n c√≥ th·ªÉ:\n",
    "\n",
    "- Ch·∫°y Cell 2 + 3 ch·ªâ 1 l·∫ßn duy nh·∫•t ƒë·ªÉ kh·ªüi t·∫°o DB v√† Collection.\n",
    "\n",
    "- Sau ƒë√≥ d√πng Cell 6 ƒë·ªÉ index t·∫•t c·∫£ data c≈©.\n",
    "\n",
    "- V·ªÅ sau ch·ªâ c·∫ßn ch·∫°y Cell 7 ƒë·ªÉ n·∫°p th√™m data m·ªõi v√†o, kh√¥ng ·∫£nh h∆∞·ªüng d·ªØ li·ªáu c≈©."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3bc986",
   "metadata": {},
   "source": [
    "# cell 8\n",
    "\n",
    "ƒê·∫£m b·∫£o ch·∫°y Cell 4 tr∆∞·ªõc Cell 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccb43624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "def time_to_seconds(time_str):\n",
    "    \"\"\"\n",
    "    Chuy·ªÉn ƒë·ªïi th·ªùi gian d·∫°ng mm:ss th√†nh gi√¢y.\n",
    "\n",
    "    Args:\n",
    "        time_str (str): Th·ªùi gian d·∫°ng mm:ss (v√≠ d·ª•: \"4:41\").\n",
    "\n",
    "    Returns:\n",
    "        float: S·ªë gi√¢y ho·∫∑c None n·∫øu l·ªói.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        minutes, seconds = map(int, time_str.split(':'))\n",
    "        return minutes * 60 + seconds\n",
    "    except ValueError:\n",
    "        print(f\"‚ùå L·ªói ƒë·ªãnh d·∫°ng th·ªùi gian: {time_str}\")\n",
    "        return None\n",
    "\n",
    "def get_frame_idx_from_time(video_path, time_start, time_end, csv_dir):\n",
    "    \"\"\"\n",
    "    T√¨m frame_idx g·∫ßn nh·∫•t v·ªõi th·ªùi gian trung b√¨nh c·ªßa kho·∫£ng [time_start, time_end].\n",
    "\n",
    "    Args:\n",
    "        video_path (str): ƒê∆∞·ªùng d·∫´n t·ªõi file video.\n",
    "        time_start (str): Th·ªùi gian b·∫Øt ƒë·∫ßu (mm:ss).\n",
    "        time_end (str): Th·ªùi gian k·∫øt th√∫c (mm:ss).\n",
    "        csv_dir (str): Th∆∞ m·ª•c ch·ª©a file CSV.\n",
    "\n",
    "    Returns:\n",
    "        int or None: frame_idx g·∫ßn nh·∫•t ho·∫∑c None n·∫øu l·ªói.\n",
    "    \"\"\"\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    csv_path = os.path.join(csv_dir, f\"{video_name}.csv\")\n",
    "\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"‚ùå Kh√¥ng t√¨m th·∫•y file CSV: {csv_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if not all(col in df.columns for col in ['pts_time', 'frame_idx', 'fps']):\n",
    "            print(f\"‚ùå File CSV {csv_path} thi·∫øu c·ªôt c·∫ßn thi·∫øt\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói ƒë·ªçc CSV {csv_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    start_sec = time_to_seconds(time_start)\n",
    "    end_sec = time_to_seconds(time_end)\n",
    "    if start_sec is None or end_sec is None:\n",
    "        return None\n",
    "\n",
    "    target_time = (start_sec + end_sec) / 2\n",
    "    df['time_diff'] = abs(df['pts_time'] - target_time)\n",
    "    closest_row = df.loc[df['time_diff'].idxmin()]\n",
    "    return int(closest_row['frame_idx'])\n",
    "\n",
    "def format_search_results(search_results, csv_dir):\n",
    "    \"\"\"\n",
    "    ƒê·ªãnh d·∫°ng k·∫øt qu·∫£ t·ª´ search_videos_by_text, nh√≥m theo video_path ƒë·ªÉ m·ªói video ch·ªâ in path m·ªôt l·∫ßn.\n",
    "\n",
    "    Args:\n",
    "        search_results (list): K·∫øt qu·∫£ t·ª´ search_videos_by_text (danh s√°ch dict v·ªõi video_path, title, time_ranges).\n",
    "        csv_dir (str): Th∆∞ m·ª•c ch·ª©a file CSV.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary v·ªõi key l√† video_path, value l√† tuple (video_name, list of (frame_idx, time_start, time_end)).\n",
    "    \"\"\"\n",
    "    grouped_results = {}\n",
    "    for res in search_results:\n",
    "        video_path = res['video_path']\n",
    "        video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "        if video_path not in grouped_results:\n",
    "            grouped_results[video_path] = (video_name, [])\n",
    "        \n",
    "        for time_start, time_end in res['time_ranges']:\n",
    "            frame_idx = get_frame_idx_from_time(video_path, time_start, time_end, csv_dir)\n",
    "            if frame_idx is not None:\n",
    "                grouped_results[video_path][1].append((frame_idx, time_start, time_end))\n",
    "    \n",
    "    return grouped_results\n",
    "\n",
    "def encode_text(text):\n",
    "    \"\"\"\n",
    "    M√£ h√≥a vƒÉn b·∫£n th√†nh vector ƒë·∫∑c tr∆∞ng b·∫±ng m√¥ h√¨nh CLIP.\n",
    "\n",
    "    Args:\n",
    "        text (str): Chu·ªói vƒÉn b·∫£n truy v·∫•n.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray or None: Vector ƒë·∫∑c tr∆∞ng c·ªßa vƒÉn b·∫£n ho·∫∑c None n·∫øu l·ªói.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        inputs = processor(\n",
    "            text=[text],\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=77\n",
    "        ).to(device)\n",
    "        with torch.no_grad():\n",
    "            text_features = model.get_text_features(**inputs)\n",
    "        return F.normalize(text_features, p=2, dim=1)[0].cpu().numpy()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói encode text: {e}\")\n",
    "        return None\n",
    "\n",
    "def format_time(seconds):\n",
    "    \"\"\"\n",
    "    Chuy·ªÉn ƒë·ªïi th·ªùi gian (gi√¢y) th√†nh ƒë·ªãnh d·∫°ng mm:ss.\n",
    "\n",
    "    Args:\n",
    "        seconds (float): Th·ªùi gian t√≠nh b·∫±ng gi√¢y.\n",
    "\n",
    "    Returns:\n",
    "        str: Chu·ªói th·ªùi gian ƒë·ªãnh d·∫°ng mm:ss.\n",
    "    \"\"\"\n",
    "    m = int(seconds // 60)\n",
    "    s = int(seconds % 60)\n",
    "    return f\"{m}:{s:02d}\"\n",
    "\n",
    "def group_timestamps(timestamps, gap_threshold=10.0):\n",
    "    \"\"\"\n",
    "    Gom c√°c timestamp g·∫ßn nhau th√†nh c√°c kho·∫£ng th·ªùi gian.\n",
    "\n",
    "    Args:\n",
    "        timestamps (list): Danh s√°ch th·ªùi gian (gi√¢y) c·∫ßn nh√≥m.\n",
    "        gap_threshold (float): Kho·∫£ng c√°ch t·ªëi ƒëa gi·ªØa hai timestamp ƒë·ªÉ xem l√† c√πng nh√≥m.\n",
    "\n",
    "    Returns:\n",
    "        list: Danh s√°ch c√°c tuple (start, end) bi·ªÉu th·ªã kho·∫£ng th·ªùi gian.\n",
    "    \"\"\"\n",
    "    if not timestamps:\n",
    "        return []\n",
    "    \n",
    "    timestamps = sorted(timestamps)\n",
    "    ranges = []\n",
    "    start = timestamps[0]\n",
    "    end = timestamps[0]\n",
    "    for t in timestamps[1:]:\n",
    "        if t - end <= gap_threshold:\n",
    "            end = t\n",
    "        else:\n",
    "            ranges.append((start, end))\n",
    "            start = t\n",
    "            end = t\n",
    "    ranges.append((start, end))\n",
    "    return ranges\n",
    "\n",
    "def search_videos_by_text(text_query, top_k=10, gap_threshold=10.0):\n",
    "    \"\"\"\n",
    "    T√¨m ki·∫øm video d·ª±a tr√™n truy v·∫•n vƒÉn b·∫£n, tr·∫£ v·ªÅ danh s√°ch video v·ªõi kho·∫£ng th·ªùi gian li√™n quan.\n",
    "\n",
    "    Args:\n",
    "        text_query (str): VƒÉn b·∫£n truy v·∫•n.\n",
    "        top_k (int): S·ªë l∆∞·ª£ng k·∫øt qu·∫£ t·ªëi ƒëa tr·∫£ v·ªÅ t·ª´ Milvus.\n",
    "        gap_threshold (float): Ng∆∞·ª°ng th·ªùi gian ƒë·ªÉ nh√≥m c√°c timestamp.\n",
    "\n",
    "    Returns:\n",
    "        list: Danh s√°ch c√°c video v·ªõi ƒë∆∞·ªùng d·∫´n, ti√™u ƒë·ªÅ v√† c√°c kho·∫£ng th·ªùi gian.\n",
    "    \"\"\"\n",
    "    text_emb = encode_text(text_query)\n",
    "    if text_emb is None:\n",
    "        return []\n",
    "\n",
    "    results = client.search(\n",
    "        collection_name=\"text_image_video_collection\",\n",
    "        data=[text_emb],\n",
    "        limit=top_k,\n",
    "        output_fields=[\"frame_path\"]\n",
    "    )\n",
    "\n",
    "    output = []\n",
    "    for hit in results[0]:\n",
    "        frame_path = hit[\"entity\"][\"frame_path\"]\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT v.video_path, v.title, fm.pts_time\n",
    "            FROM frame_mappings fm\n",
    "            JOIN videos v ON fm.video_id = v.id\n",
    "            WHERE fm.frame_path=%s\n",
    "        \"\"\", (frame_path,))\n",
    "        row = cur.fetchone()\n",
    "        if row:\n",
    "            video_path, title, pts_time = row\n",
    "            output.append((video_path, title, pts_time))\n",
    "\n",
    "    grouped_results = {}\n",
    "    for video_path, title, pts_time in output:\n",
    "        if video_path not in grouped_results:\n",
    "            grouped_results[video_path] = {\"title\": title, \"timestamps\": []}\n",
    "        grouped_results[video_path][\"timestamps\"].append(pts_time)\n",
    "\n",
    "    final_results = []\n",
    "    for video_path, data in grouped_results.items():\n",
    "        time_ranges = group_timestamps(data[\"timestamps\"], gap_threshold=gap_threshold)\n",
    "        final_results.append({\n",
    "            \"video_path\": video_path,\n",
    "            \"title\": data[\"title\"],\n",
    "            \"time_ranges\": [(format_time(s), format_time(e)) for s, e in time_ranges]\n",
    "        })\n",
    "\n",
    "    return final_results\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def keyframe_path_from_frame_idx(video_path, frame_idx, csv_dir, frame_root):\n",
    "    \"\"\"\n",
    "    Map frame_idx -> n (theo CSV) r·ªìi t√¨m file ·∫£nh keyframe t∆∞∆°ng ·ª©ng.\n",
    "    Tr·∫£ v·ªÅ path ·∫£nh ho·∫∑c None n·∫øu kh√¥ng t√¨m th·∫•y.\n",
    "    \"\"\"\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    csv_path   = os.path.join(csv_dir, f\"{video_name}.csv\")\n",
    "    dir_path   = os.path.join(frame_root, video_name)   # ‚úÖ s·ª≠a: b·ªè group_name trung gian\n",
    "\n",
    "    if not os.path.exists(csv_path):\n",
    "        return None\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    # C·∫ßn c·ªôt 'n' v√† 'frame_idx'\n",
    "    if not all(c in df.columns for c in [\"n\", \"frame_idx\"]):\n",
    "        return None\n",
    "\n",
    "    # T√¨m h√†ng c√≥ frame_idx g·∫ßn nh·∫•t v·ªõi frame_idx y√™u c·∫ßu\n",
    "    idx = (df[\"frame_idx\"] - int(frame_idx)).abs().idxmin()\n",
    "    n_val = int(df.loc[idx, \"n\"])\n",
    "\n",
    "    # Th·ª≠ c√°c bi·∫øn th·ªÉ t√™n file\n",
    "    candidates = []\n",
    "    for stem in [n_val, f\"{n_val:03d}\", f\"{n_val:04d}\", frame_idx, f\"{int(frame_idx):03d}\", f\"{int(frame_idx):04d}\"]:\n",
    "        for ext in (\"jpg\", \"jpeg\", \"png\"):\n",
    "            candidates.append(os.path.join(dir_path, f\"{stem}.{ext}\"))\n",
    "\n",
    "    for p in candidates:\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c376a499",
   "metadata": {},
   "source": [
    "## diÃ£ch t∆∞ÃÄ vi√™Ã£t sang anh ƒë√™Ãâ queey neÃÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "998bbf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå K·∫øt qu·∫£ t√¨m ki·∫øm cho: \"fire truck\"\n",
      "\n",
      "üìÇ Path: D:/Big_project_2025/Video_Similarity_Search/data/video/L21_V001.mp4\n",
      "L21_V001, Frame Idx: 20235 üëâ Xu·∫•t hi·ªán t·ª´ 11:11 ƒë·∫øn 11:18\n",
      "L21_V001, Frame Idx: 27908 üëâ Xu·∫•t hi·ªán t·ª´ 15:30 ƒë·∫øn 15:30\n",
      "L21_V001, Frame Idx: 36318 üëâ Xu·∫•t hi·ªán t·ª´ 20:10 ƒë·∫øn 20:10\n",
      "L21_V001, Frame Idx: 37167 üëâ Xu·∫•t hi·ªán t·ª´ 20:29 ƒë·∫øn 20:45\n",
      "\n",
      "üìÇ Path: D:/Big_project_2025/Video_Similarity_Search/data/video/L21_V002.mp4\n",
      "L21_V002, Frame Idx: 12045 üëâ Xu·∫•t hi·ªán t·ª´ 6:26 ƒë·∫øn 6:58\n",
      "L21_V002, Frame Idx: 13083 üëâ Xu·∫•t hi·ªán t·ª´ 7:16 ƒë·∫øn 7:16\n",
      "L21_V002, Frame Idx: 14933 üëâ Xu·∫•t hi·ªán t·ª´ 8:12 ƒë·∫øn 8:21\n",
      "\n",
      "üìÇ Path: D:/Big_project_2025/Video_Similarity_Search/data/video/L21_V003.mp4\n",
      "L21_V003, Frame Idx: 12811 üëâ Xu·∫•t hi·ªán t·ª´ 8:32 ƒë·∫øn 8:38\n",
      "L21_V003, Frame Idx: 19380 üëâ Xu·∫•t hi·ªán t·ª´ 12:55 ƒë·∫øn 12:55\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ================== Demo ==================\n",
    "# VƒÉn b·∫£n c·∫ßn d·ªãch\n",
    "text_vi = \"xe c∆∞ÃÅu hoÃâa\"\n",
    "result = GoogleTranslator(source='vi', target='en').translate(text_vi)\n",
    "\n",
    "# T√¨m ki·∫øm video b·∫±ng h√†m g·ªëc\n",
    "query = result  # V√≠ d·ª•:\n",
    "search_results = search_videos_by_text(query, top_k=20, gap_threshold=15.0)\n",
    "\n",
    "# Chuy·ªÉn ƒë·ªïi k·∫øt qu·∫£ sang ƒë·ªãnh d·∫°ng y√™u c·∫ßu\n",
    "results = format_search_results(search_results, csv_dir=CSV_DIR)\n",
    "\n",
    "# In k·∫øt qu·∫£\n",
    "print(f\"üìå K·∫øt qu·∫£ t√¨m ki·∫øm cho: \\\"{query}\\\"\")\n",
    "for video_path, (video_name, frames) in results.items():\n",
    "    print(f\"\\nüìÇ Path: {video_path}\")\n",
    "    for frame_idx, time_start, time_end in frames:\n",
    "        print(f\"{video_name}, Frame Idx: {frame_idx} üëâ Xu·∫•t hi·ªán t·ª´ {time_start} ƒë·∫øn {time_end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f259ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K·∫øt qu·∫£ t√¨m ki·∫øm cho: \"Many fish are swimming\"\n",
      "\n",
      "Video: L21_V001\n",
      "Path: D:/Big_project_2025/Video_Similarity_Search/data/video/L21_V001.mp4\n",
      "Frame Idx: 10868 -- Xu·∫•t hi·ªán t·ª´ 6:02 ƒë·∫øn 6:02 -- Path: D:\\Big_project_2025\\Video_Similarity_Search\\data\\key_frame\\L21_V001\\087.jpg\n",
      "Frame Idx: 31560 -- Xu·∫•t hi·ªán t·ª´ 17:11 ƒë·∫øn 17:49 -- Path: D:\\Big_project_2025\\Video_Similarity_Search\\data\\key_frame\\L21_V001\\253.jpg\n",
      "Frame Idx: 32622 -- Xu·∫•t hi·ªán t·ª´ 18:07 ƒë·∫øn 18:11 -- Path: D:\\Big_project_2025\\Video_Similarity_Search\\data\\key_frame\\L21_V001\\261.jpg\n",
      "Frame Idx: 34961 -- Xu·∫•t hi·ªán t·ª´ 19:22 ƒë·∫øn 19:31 -- Path: D:\\Big_project_2025\\Video_Similarity_Search\\data\\key_frame\\L21_V001\\282.jpg\n",
      "\n",
      "Video: L21_V003\n",
      "Path: D:/Big_project_2025/Video_Similarity_Search/data/video/L21_V003.mp4\n",
      "Frame Idx: 5970 -- Xu·∫•t hi·ªán t·ª´ 3:51 ƒë·∫øn 4:07 -- Path: D:\\Big_project_2025\\Video_Similarity_Search\\data\\key_frame\\L21_V003\\060.jpg\n",
      "Frame Idx: 9060 -- Xu·∫•t hi·ªán t·ª´ 5:57 ƒë·∫øn 6:06 -- Path: D:\\Big_project_2025\\Video_Similarity_Search\\data\\key_frame\\L21_V003\\090.jpg\n",
      "Frame Idx: 14610 -- Xu·∫•t hi·ªán t·ª´ 9:37 ƒë·∫øn 9:49 -- Path: D:\\Big_project_2025\\Video_Similarity_Search\\data\\key_frame\\L21_V003\\149.jpg\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "import os\n",
    "\n",
    "# ---------------- Demo ----------------\n",
    "# VƒÉn b·∫£n ti·∫øng Vi·ªát c·∫ßn t√¨m\n",
    "text_vi = \"nhi√™ÃÄu con caÃÅ ƒëang b∆°i\"\n",
    "# D·ªãch sang ti·∫øng Anh ƒë·ªÉ match v·ªõi CLIP\n",
    "text_en = GoogleTranslator(source='vi', target='en').translate(text_vi)\n",
    "\n",
    "# T√¨m ki·∫øm video d·ª±a tr√™n truy v·∫•n vƒÉn b·∫£n\n",
    "search_results = search_videos_by_text(text_en, top_k=20, gap_threshold=15.0)\n",
    "\n",
    "# Chuy·ªÉn ƒë·ªïi k·∫øt qu·∫£ sang ƒë·ªãnh d·∫°ng video_path -> (video_name, list of (frame_idx, time_start, time_end))\n",
    "results = format_search_results(search_results, csv_dir=CSV_DIR)\n",
    "\n",
    "# In k·∫øt qu·∫£\n",
    "print(f\"K·∫øt qu·∫£ t√¨m ki·∫øm cho: \\\"{text_en}\\\"\")\n",
    "for video_path, (video_name, frames) in results.items():\n",
    "    print(f\"\\nVideo: {video_name}\")\n",
    "    print(f\"Path: {video_path}\")\n",
    "\n",
    "    for frame_idx, time_start, time_end in frames:\n",
    "        img_path = keyframe_path_from_frame_idx(\n",
    "            video_path=video_path,\n",
    "            frame_idx=frame_idx,\n",
    "            csv_dir=CSV_DIR,\n",
    "            frame_root=FRAME_DIR\n",
    "        )\n",
    "        img_path_str = img_path if img_path else \"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ·∫£nh\"\n",
    "        print(f\"Frame Idx: {frame_idx} -- Xu·∫•t hi·ªán t·ª´ {time_start} ƒë·∫øn {time_end} -- Path: {img_path_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c4ae32",
   "metadata": {},
   "source": [
    "## üìù Ph√¢n t√≠ch l·∫°i pipeline\n",
    "\n",
    "1. **Video ‚Üí Frame ‚Üí Embedding**\n",
    "\n",
    "   * Video ƒë∆∞·ª£c chia th√†nh **c√°c keyframe**.\n",
    "   * M·ªói frame c√≥ metadata ƒë∆∞·ª£c l∆∞u v√†o CSV/DB:\n",
    "\n",
    "     * **n**: s·ªë th·ª© t·ª± keyframe.\n",
    "     * **pts\\_time**: th·ªùi ƒëi·ªÉm xu·∫•t hi·ªán frame trong video (t√≠nh b·∫±ng gi√¢y).\n",
    "     * **fps**: frame per second (v√≠ d·ª•: 30 fps).\n",
    "     * **frame\\_idx**: ch·ªâ s·ªë frame trong to√†n video (fps √ó th·ªùi gian).\n",
    "\n",
    "   üëâ V√≠ d·ª•:\n",
    "\n",
    "   ```\n",
    "   n=2, pts_time=3.0, fps=30.0, frame_idx=90\n",
    "   ```\n",
    "\n",
    "   nghƒ©a l√† frame s·ªë 90 (t·∫°i gi√¢y th·ª© 3.0) ƒë∆∞·ª£c ch·ªçn l√†m keyframe th·ª© 2.\n",
    "\n",
    "2. **Index & L∆∞u tr·ªØ**\n",
    "\n",
    "   * Embedding c·ªßa t·ª´ng frame ƒë∆∞·ª£c t√≠nh b·∫±ng CLIP.\n",
    "   * Vector n√†y ƒë∆∞·ª£c l∆∞u v√†o Milvus c√πng metadata: `{frame_path, video_id, pts_time, frame_idx}`.\n",
    "\n",
    "3. **T√¨m ki·∫øm (Text ‚Üí Embedding ‚Üí Milvus)**\n",
    "\n",
    "   * Ng∆∞·ªùi d√πng nh·∫≠p text (VD: `\"fish swimming\"`).\n",
    "   * Text ƒë∆∞·ª£c encode th√†nh vector b·∫±ng CLIP.\n",
    "   * Milvus t√¨m trong vector database ‚Üí tr·∫£ v·ªÅ top-K frame g·∫ßn nh·∫•t.\n",
    "   * PostgreSQL/CSV ƒë∆∞·ª£c query theo **frame\\_idx ho·∫∑c pts\\_time** ƒë·ªÉ bi·∫øt frame n√†y n·∫±m ·ªü gi√¢y n√†o, thu·ªôc video n√†o.\n",
    "   * K·∫øt qu·∫£ cu·ªëi c√πng: **video + kho·∫£ng th·ªùi gian ch·ª©a frame**.\n",
    "\n",
    "\n",
    "\n",
    "# üîé √ù nghƒ©a c·ªßa b·∫£ng `n, pts_time, fps, frame_idx`\n",
    "\n",
    "## 1. Nguy√™n t·∫Øc c∆° b·∫£n\n",
    "\n",
    "* Trong file CSV c√≥ (v√≠ d·ª• `L21_V001.csv`):\n",
    "\n",
    "  ```\n",
    "  n, pts_time, fps, frame_idx\n",
    "  1, 0.0, 30.0, 0\n",
    "  2, 3.0, 30.0, 90\n",
    "  3, 10.0, 30.0, 300\n",
    "  ...\n",
    "  ```\n",
    "* C√°c th√¥ng tin quan tr·ªçng:\n",
    "\n",
    "  * `pts_time`: th·ªùi gian (t√≠nh b·∫±ng gi√¢y).\n",
    "  * `fps`: s·ªë khung h√¨nh m·ªói gi√¢y (frames per second).\n",
    "  * `frame_idx`: ch·ªâ s·ªë frame t∆∞∆°ng ·ª©ng v·ªõi th·ªùi gian ƒë√≥.\n",
    "\n",
    "üëâ C√¥ng th·ª©c c∆° b·∫£n:\n",
    "\n",
    "$$\n",
    "frame\\_idx = time\\_in\\_seconds \\times fps\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 2. V√≠ d·ª• v·ªõi **Frame Idx = 8820**\n",
    "\n",
    "* Gi·∫£ s·ª≠ video c√≥ **fps = 30**.\n",
    "* T√≠nh ng∆∞·ª£c l·∫°i th·ªùi gian:\n",
    "\n",
    "  $$\n",
    "  time\\_in\\_seconds = \\frac{frame\\_idx}{fps} = \\frac{8820}{30} = 294\\ (gi√¢y)\n",
    "  $$\n",
    "* 294 gi√¢y = 4 ph√∫t 54 gi√¢y (‚âà **4:54**).\n",
    "\n",
    "Trong log c·ªßa b·∫°n, h·ªá th·ªëng hi·ªÉn th·ªã:\n",
    "\n",
    "```\n",
    "Xu·∫•t hi·ªán t·ª´ 4:41 ƒë·∫øn 5:11\n",
    "```\n",
    "\n",
    "üëâ L√Ω do c√≥ **kho·∫£ng \\[4:41 ‚Äì 5:11]**:\n",
    "\n",
    "* Khi search, b·∫°n l·∫•y nhi·ªÅu frame g·∫ßn nhau (theo pts\\_time).\n",
    "* Sau ƒë√≥ d√πng h√†m `group_timestamps` ƒë·ªÉ gom l·∫°i th√†nh **1 kho·∫£ng li√™n t·ª•c** (c√°ch nhau ‚â§ 10s).\n",
    "* Do ƒë√≥ frame 8820 (t√≠nh to√°n ra \\~4:54) n·∫±m trong **cluster timestamps** t·ª´ \\~4:41 (281s) ‚Üí \\~5:11 (311s).\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "‚úÖ **K·∫øt lu·∫≠n**\n",
    "\n",
    "* **Frame idx (8820)** t√≠nh ƒë∆∞·ª£c t·ª´:\n",
    "\n",
    "  $$\n",
    "  frame\\_idx = time \\times fps\n",
    "  $$\n",
    "* **Kho·∫£ng th·ªùi gian \\[4:41 ‚Äì 5:11]** ƒë∆∞·ª£c t·∫°o ra do  **gom c√°c timestamps g·∫ßn nhau th√†nh 1 cluster**, trong ƒë√≥ 8820 n·∫±m gi·ªØa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e48805",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
